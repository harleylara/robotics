---
title: Fundamentals of Probability
description: Losing and finding my mind
---

"Probability is too important to be left to the experts." @hammingArtProbabilityScientists1991 chapter 1.

## Motivation

**Personal motivation**: I would be one of the first to ask, why some notes on probability in the context of "robotics notes"? my personal answer is because there are simply many fields that extend to the area of robotics that require foundations in probability, to mention some of them; state estimation, deep learning, machine learning, gausing processes, PAC Learning and many more. Therefore, the main purpose of these notes is to lay the necessary foundations in the area of probability in order to be able to explore more areas of robotics later on.

In addition to the motivation to expand my knowlege-base in robotics it is fair to mention the motivations sown by other people, in this case [Prof. Dr. Alexander Asteroth](https://www.h-brs.de/de/inf/prof-dr-alexander-asteroth) who in both his courses "Bayesian Inference and Gaussian Processes" and "Complexity, Randomization, Approximation and PAC-Learning" made me rediscover how fascinating this area is.

Honestly, this note is also driven by a desire to learn and to explore beyond formulas and procedures -- to dive into ideas.

## Historical Background

See: @stiglerHistoryStatisticsMeasurement1986

## About Events

Equivalent terms: Event, experiment, process


<Drawio file="probability.drawio" page="0">
    Types of processes and outcomes.
</Drawio>

<Definition term="Random Event">
A random event is the complement of a deterministic event in the sense that if a deterministic event is one whose outcome is completely predictable, by complementarity the outcome of a random event is not fully predictable.

Source: Introduction to Bayesian Scientific Computing: Ten Lectures on Subjective Computing (2007), section 1.1
</Definition>

I took the following excerpt from the from [Introduction to Bayesian Scientific Computing](https://link.springer.com/book/10.1007/978-0-387-73394-4) and decided to copy it as it is written because I think it is very well put:

*"[...] randomness means lack of information. The degree of information, or more generally, our belief about the outcome of a random event, is expressed in terms of probability."* @calvettiIntroductionBayesianScientific2007 in section 1.1.

*"That said, it is clear that the concept of probability has a **subjective** component, since it is a subjective matter to decide what is reasonable to believe, and what previous experience the belief is based on. The concept of probability advocated in this book is called **subjective probability**, which is often a synonym of **Bayesian probability**"*

export const think_modelling_random = "How can we model a random process or 'experiment' in away that allow us to predict the outcome? For example how can we define the process of throwing a die?"

<Think>
{think_modelling_random}
</Think>

The answer to this is provided by the concept of **Probability Space**: is a mathematical construct that provides a formal model of a random process or "experiment". [Probability Space - Wikipedia](https://en.wikipedia.org/wiki/Probability_space)

Let's break it down.

Side track to the rabbit hole:
- [What is Random?](https://www.youtube.com/watch?v=9rIy0xY99a0) by Vsauce
- [what is NOT Random?](https://www.youtube.com/watch?v=sMb00lz-IfE) by Veritasium
- [Computational irreducibility - Wolfram MathWorld](https://mathworld.wolfram.com/ComputationalIrreducibility.html)
    - [Stephen Wolfram: ChatGPT and the Nature of Truth, Reality & Computation | Lex Fridman Podcast #376](https://youtu.be/PdE-waSx-d8?t=737), talking about Computational irreducibility.

## The Building Blocks

The formalization of the probability theory is largely due to [Andrey Kolmogorov](https://en.wikipedia.org/wiki/Andrey_Kolmogorov), in his book @kolmogoroffGrundbegriffeWahrscheinlichkeitsrechnung1933 (later tranlated into @kolmogorovFoundationsTheoryProbability1960), who a as @jacodProbabilityEssentials2004 mention at the beginning of chapter 1, Kolmogorov *"[...] saw the connection between the ideas of Borel and Lebesgue and probability theory and gave probability theory its rigorous basis of measurement theory."*, but *"[...] Paul LÃ©vy set the tone for modern Probability [...]"*. In addition, @jaynesProbabilityTheoryLogic2003 provides a comparative view of Kolmogorov's approach on probability (and others) and constracts it with the ideas derived in his book ("Probability Theory: The logic of science"),

Probability as we know it today has its roots in [Measure Theory](https://en.wikipedia.org/wiki/Measure_(mathematics)). Measure Theory provides a framework for generalizing and formalizing the concept of "measure" (in the most generic extension of the word) to any context. Measures are fundamental to probability theory, the theory of integration and others areas. A good resource to explore is @taoIntroductionMeasureTheory2011. In simple words, measure theory seeks to assign numbers to "things" by figuring out whether they can actually be measured, and by "things" we mean any kind of things -- physical or abstract --, such as; numbers, symbols, geometric shapes, variables, or even other "collection of things", and I know, the term "things" is not very concrete or formal so in mathematics it is usually referred as **set**.

And what does all this have to do with probability? Well, before explaining the concepts of probability, let me introduce an abstraction tool in term of wording which (hopefully) will help to generalize the ideas and understand the underlaying principles for probability.

In probability the term "events" is used extensibly, so if necessary use the following table to be able to generalize ideas of probability to other domains, or on the contrary to concretize ideas of measure theory in terms of probability.

| Measure Theory          | Probability      |
|-------------------------|------------------|
| Measurable sets         | Events           |
| Element/member of a set | Event            |
| Measurable functions    | Random variables |

From @jacodProbabilityEssentials2004 (Probability Essentials) *"The theory of probability aims towards a mathematical theory which describes such phenomena. This theory -- the probability space -- contains three main ingredients"*:
- **Sample space**: $\Omega$
- **Event space**: $\ssE$
- **The probability measure**: $P$

Note: the concept of probability space will be discussed later, but in essence it is derived from the concept of [measure space](https://en.wikipedia.org/wiki/Measure_space) of Measure theory.

At this point we already have a hint (the necessary ingredients) that will help us answer the question: {think_modelling_random}. Now, let's dissect each individual ingredient and its inner workings.

### Sample Space

If when you read the word "space" you think of a physical space â€” maybe 3D, 2D, 1D, or even N-dimensional â€” then you're thinking in terms of **Euclidean spaces**, and you're not far from the intuition behind a **sample space**.
And if what first came to your mind was outer space... well, that shows you have a great imagination.

Now, if we push the idea even further and allow for **non-physical spaces**, accepting **abstract spaces**, we open the door to working in much more general settings, such as:
- The space of outcomes when flipping a coin.
- The space of outcomes when rolling a die.

In this way, the concept of "space" becomes a structure that can be as concrete or as abstract as needed to model the situation we want to study. Thus, you can intuitively think of a sample space as the space that lists all possibilities. For example, 
- In a 3D space, the sample space would be all the 3D coordinates â€” that is, $\sR^3$.
- In the space of flipping a coin, the possibilities are simply: $\{\textrm{heads, tails}\}$.

With this intuition in place we can define:

<Definition term="Sample space">
Denoted $\Omega$, also known as state space, can be any finite or infinite set, meaning that the sample space is a set of **ALL** possible outcomes of an experiment.
</Definition>

For example if you throw a die with 6 faces all the possible outcomes can be represented as:

<Equation>
    $$
    \Omega = \{1,2,3,4,5,6\}
    $$
    Sample space of throwing a 6 faces die.
</Equation>

If the experiment is throwing two (independent) coins the sample space is as follow:

<Equation>
    $$
    \Omega = \{hh, tt, ht, th\}\text{, where } h \text { is head and } t \text{ is tail}
    $$
    Sample space of throwing two (independent) coins.
</Equation>

<Drawio file="probability.drawio" page="7">
    Sample space examples.
</Drawio>


### Event Space

With this intuition of sample space, now we can start exploring the space itself and we can try to find "sub-spaces" -- subsets within the defined space -- that we can measure. The problem is that this is not an easy task, for example think the space of all real numbers from zero to one:

$$ \Omega = [0,1] = \{x \in \sR \, \vert \, 0 \leq x \leq 1 \} $$

<Think>
can you think of "sub-spaces" that can be derived from this space ?
</Think>

Note: I'm using the word "sub-spaces" to refer to the more formal concept of **subsets**.

Some examples:
- $\{1,2,3,4\}$ (measurable)
- all the rationals (measurable)
- all the irrationals (measurable)
- cantor set (measurable)
- vitaly set (non-measurable)

As you can see not all of them are measurable, and this is exactly a mathematician named [Giuseppe Vitaly](https://en.wikipedia.org/wiki/Giuseppe_Vitali) found, that not all subsets of a space can be measurable. Luckily for us, in probability we don't have to deal with these unruly sets.

In mathematics there is a way of referring to the collection of **all sets in a space**, this is called **powerset** ( @taoIntroductionMeasureTheory2011 refer to it as *discrete algebra* ), and is usually denoted as $2^\Omega$ or $\mathcal{P}(\Omega)$, but be careful, because as you can see in our previous example with the set of real numbers, there are spaces in the powerset that may contain subsets that are not measurable, and including them in our analysis would cause us problems. As @michaelbetancourtProbabilityTheoryScientists2018 states: *"[...] we often want to consider not the entire power set but rather a restriction of the power set that avoids any pathological sets that might be hiding."*

But you may be wondering: how do we filter or restrict only those sets that have nice properties and are measurable? What are the properties that determine whether a set is measurable or not?
Well, this is exactly what the Measure Theory branch of mathematics studies, @follandRealAnalysisModern1999 in section 1.2 of the book introduces the concept of **Algebra**, which he then extends to **Sigma-algebra**, this is exactly the solution to our previous question; **Algebras and Sigma-Algebras** define certain properties -- which we will discuss next -- that help us to filter or restrict consistent sets that can be measurable.

<Definition term="Algebra">
Let $\sX$ be a **non empty set** (our space). A collection $\ssE$ of subsets of $\sX$ is a **Algebra** if:
(i). If $\sE \in \ssE$ then $\scE \in \ssE$. In words: Pick some set from $\sX$, for example $\sE$, if $\sE$ is in the algebra its complement is also in the algebra.
(ii). If $\sE_1, \dots, \sE_{n} \in \ssE$ then $\bigcup_{j=1}^{n} \sE_j \in \ssE$. In words: If a **finite** collection of sets ($\sE_1, \dots \sE_{n}$) is in $\ssE$ then the union of all of them is also in $\ssE$.
</Definition>

<Drawio file="probability.drawio" page="3">
    Illustration of an Algebra.
</Drawio>

From these two simple but powerful properties of Algebras we can derive more properties:
- $\Omega \in \ssE$ and $\emptyset \in \ssE$. If we place our complete space, in this case demonimated $\Omega$, the first property of Algebras (closed under complements) tells us that we also have to include its complement.
- If $\sE \in \ssE$ then $\scE \in \ssE$. Property (i) by itself: Closed under complements.
- If $\sE_1, \dots, \sE_{n} \in \ssE$ then $\bigcup_{j=1}^{n} \sE_j \in \ssE$. Property (ii) by itself: Closed under **finite** unions.
- If $\sE_1, \dots, \sE_{n} \in \ssE$ then $\bigcap_{j=1}^{n} \sE_j \in \ssE$. Closed under **finite** intersections. This property may not be obvious at first sight, but it is simply a consequence of (i) and (ii).

<Definition term="Finite set">
In mathematics, particularly set theory, a finite set is a set that has a finite number of elements.. Example the set of all outcomes of throwing a dice ${1,2,3,4,5,6}$.

Source: [Finite set - Wikipedia](https://en.wikipedia.org/wiki/Finite_set)
</Definition>

Derivation of **closed under finite intersections**:

You can simply invoke De Morgan law:  $\sA \cap \sB = (\scA \cup \scB)^{\complement}$, so that property (i) and (ii) cause property of closed under intersections. Here is a visual illustration of De Morgan law.

<Drawio file="probability.drawio" page="9">
    Illustration of De Morgan law.
</Drawio>

To keep this brief, as an exercise, you can generalize this rule for $n$-sets.

<Think>
Why are we doing all this, I thought we were going to talk about Event Space?
</Think>

I don't blame you for thinking that, but trust me â€” we'll get there soon, and hopefully, you'll have an Aha! moment when we introduce the Event Space. Think of this paragraph as a quick stop at the shore to catch your breath before we head back into the water.

Before we get back just a quick recap:
- An abstract space (like the sample space) ...
- can contain subsets that are not measurable ...
- so we can filter or restrict them with the properties of the Algebras

At this point we have made the assumption that we are working with **FINITE unions**, the problem is that in Probability it is not enough, and sometimes we have to work with **Countable unions**. As @taoIntroductionMeasureTheory2011 explains in section 1.4.2, this property of infinite unions is also important in integration theory, and @follandRealAnalysisModern1999 in section 1.1 explains more details about it. Then, to work with **Countable unions** we must use not Algebras, but [**Sigma-algebras**](https://en.wikipedia.org/wiki/%CE%A3-algebra).


If you're thinking, "wait, another concept?" ... yes, another concept but don't worry it will be easy, I promise.

<Definition term="Sigma-algebra">
  A $\sigma$-algebra, also known as $\sigma$-field or borel-field, **is an algebra** that is closed under countable unions.
</Definition>

You may be thinking, "Wait, that's it?". Actually yes, a $\sigma$-algebra is an extension of Algebras that allows us to work with countable unions, so all the properties you learned from an Algebras are present on a $\sigma$-algebra. But in favor of completness, here is an expansion of the $\sigma$-algebra definition.

<Definition term="Sigma-algebra (explicit)">
We assume a $\sigma$-algebra denoted $\ssE$ if it satisfies the following properties:

(i). If $\sE \in \ssE$ then $\scE \in \ssE$. In words: The same property (i) of Algebras.

(ii). If $\sE_i \in \ssE, \forall i \in \sN$, then $\bigcup_{i=1}^{\infty} \sE_i \in \ssE$. In words: If a **countable** collection of sets is in $\ssE$ then the union of all of them is also in $\ssE$.
</Definition>

Just as properties (i) and (ii) of an [Algebra](#algebra) imply closure under finite intersections, properties (i) and (ii) of a sigma-algebra imply closure under countable intersections. Keep in mind that for any finite collection of sets $\sA_1, \dots, \sA_n \in \ssE$ the union $\bigcup_{i=1}^{n} \sA_i$ is just a particular case of the countable union, Therefore the properties (i) and (ii) of a $\sigma$-algebra implies finite unions, hence any $\sigma$-algebra is a algebra but there are algebras that are not $\sigma$-algebras.

In simple mathematical words:
- A algebra is **closed** under **finite** unions and complements.
- A Sigma-algebra is **closed** under **countable** unions and complements.

Note: The word "closed" is like a safety belt, which ensures that we can do operations such as complements, unions or interceptions without leaving our space (our set). Why? consistency... But why?  this is out of the scope of probability and these notes so I recommend you to see; @taoIntroductionMeasureTheory2011 and @follandRealAnalysisModern1999.

<Definition term='Countable set'>
In mathematics, a set is countable if either it is finite or it can be made in one to one correspondence with the set of natural numbers ([A bijection, bijective function, or one-to-one correspondence](https://en.wikipedia.org/wiki/Bijection)).

Source: [Countable set - Wikipedia](https://en.wikipedia.org/wiki/Countable_set)
</Definition>

So,
- the smallest Sigma-algebra ( @taoIntroductionMeasureTheory2011 calls it the *trivial algebra*) is: $\{\emptyset, \sX\}$, also denoted as $\sigma(\sX)$
- the largest Sigma-algebra is: the power set $2^\Omega$

|               | Algebra                     | Sigma-algebra                  |
|---------------|-----------------------------|--------------------------------|
| Unions        | finite only                 | countable (finite or infinite) |
| Complements   | yes                         | yes                            |
| Intersections | yes (using De Morgan's law) | yes (using De Morgan's law)    |


Side track to the rabbit hole:
- [The Man Who Almost Broke Math (And Himself...)](https://www.youtube.com/watch?v=_cr46G2K5Fo), about [Georg Cantor](https://en.wikipedia.org/wiki/Georg_Cantor) and the historical background that laid the foundations of set theory, including explanation of the [Vitali set](https://en.wikipedia.org/wiki/Vitali_set), [timestamp to Vitali set](https://youtu.be/_cr46G2K5Fo?t=1069).

As promised, here we are, the **event space**, the punchline is that the **event space** is just a $\sigma$-algebra, therefore the definition of $\sigma$-algebra is the definition of event space. ðŸ¤¯

<Definition term='Event Space'>
The event space is a $\sigma$-algebra that contains ALL possible events for a given experiment.

Source: [Event Space Probability - Statistics How To](https://www.statisticshowto.com/event-space-probability/)
</Definition>

Here are some concrete examples:

<Drawio file="probability.drawio" page="8">
    Power set of the sample space.
</Drawio>

With these two concepts -- [sample space](#sample-space) and [event space](#event-space) -- we can construct what is called a "measurable space":

<Equation>
Measurable space, $(\Omega, \ssE)$:

    Which is form by a pair $(\Omega, \ssE)$, where:
    - $\Omega$ is the sample space, representing the set of all possible outcomes.
    - $\ssE$ is the event space, a collection of subsets of $\Omega$ that is closed under countable unions, countable intersections, and complementsâ€”formally, a $\sigma$-algebra.
</Equation>

In measure theory, this pair $(\Omega, \ssE)$ defines a structure -- measurable space -- on which a measure can be meaningfully defined. This framework allows for the rigorous assignment of values (such as probabilities) to subsets of $\Omega$ that belong to the $\sigma$-algebra $\ssE$.

### The Probability Measure

As mentioned at the beginning of the [The Building Blocks](#the-building-blocks) section, the third and final missing piece of the **probability triplet** is the **probability measure**.

I want to remind you of the measurable space $(\Omega, \ssE)$. Maybe it will help you to conceptualize it as an abstract space with defined states (the sample space), and a collection f subsets that we are interested in analyzing (the event space). However, we still lack a way to <ins>measure</ins> or **assign values** to each of the elements of the event space over the sample space. Essentially, we need a way to map (measure) from an set in $\ssE$ (event space) to a real number. The keyword here is **"measure"**, which if we think of it in geometrical terms (Euclidean spaces) we easily associate it with length, area or volume but we could also **"measure"** other magnitudes such as mass, or probability of an event to happen. 

Again, measure theory studies the concept of [measure](https://en.wikipedia.org/wiki/Measure_(mathematics)) and generalizes it so that we can use it in abstract spaces like $\{head,tail\}$ where thinking in terms of length, area or volume is not feasible. This **measure** is carried out by means of a **set function** denoted by $\mu$, which is called a **measure function** or sometimes just **measure**.

<Drawio file="probability.drawio" page="10">
    Measure function.
</Drawio>

<Definition term="Measure function">
Is a function that maps from a $\sigma$-algebra to the positive reals: $\mu: \ssE \rightarrow \sR^{+}$ such that:
(i) $\mu(\emptyset) = 0$
(ii) $\\mu(\bigcup_{i}^{\infty}\sE_i ) = \sum_{i}^{\infty} \mu(\sE_i)$ for a **pairwise disjoint** $\sE_i \in \ssE, i \in \sN$ ($\sigma$-additivity)
</Definition>

From: @taoIntroductionMeasureTheory2011, Definition 1.4.27

Note to Harley: Should I add the [properties of a measure?](https://en.wikipedia.org/wiki/Measure_(mathematics)#Basic_properties)

**measure space** is a triplet $(\sS, \ssE, \mu)$, where $(\sS, \ssE)$ is a **measurable space** and $\mu$ is a measure on $\ssE$.

Okay, and you might be wondering; *I thought we were going to talk about something called "probability measure"*, and you are absolutely right that is the goal, but as you might guess at this point the whole idea of **measure** and **measure function** are fundamental concepts to help us understand **probability measure**.

It turns out that there are [classes of measures](https://en.wikipedia.org/wiki/Measure_(mathematics)#Instances), but in probability we are interested in our **measure function** mapping to the interval $[0, 1]$, so it is called a **probability measure**.

<Drawio file="probability.drawio" page="11">
    Probability measure.
</Drawio>

<Definition term="Probability measure">
A probability measure defined on a $\sigma$-algebra $\ssE$ of $\Omega$ is a **measure function** (or simply measure), denoted with $P \,:\, \ssE \rightarrow [0,1]$ that satisfies:
(i) $P(\Omega) = 1$
(ii) $P(\bigcup_{i}^{\infty}\sE_i ) = \sum_{i}^{\infty} P(\sE_i)$ for a **pairwise disjoint** $\sE_i \in \ssE, i \in \sN$ ($\sigma$-additivity)
</Definition>

Probability space is a measure space $(\sS, \ssE, P)$, where $P$ is a probability measure on $\ssE$.

| Measure Theory   | Probability Theory    | Description                                                    |
|------------------|-----------------------|----------------------------------------------------------------|
| abstract space   | sample space $\Omega$ | all possible states $w \in \Omega$                             |
| $\sigma$-algebra | event space $\ssE$    | set of all possible events $\sE \in \ssE$ that one can measure |
| measure function | probability function  | mapping from $\sigma$-algebra to $[0,1]$                       |

For an intuition about functions, see the note [On Functions](functions).

Taking back the example of trowing a die,....

Just an arbitrary example:
- Sample space $\Omega = \{1, 2, 3\}$
- Event space: the power set $2^{\Omega} = \{ \{\},\{1\},\{2\},\{3\},\{1,2\},\{2,3\},\{1,3\},\{1,2,3\}\}$ 
- The probability measure: $P(1) = 1/4$, $P(2) = 1/4$, $P(3) = 1/2$

Do you see the problem with the probability measure?

## Conditional Probability and Independence

## Random Variable

For this section, I spent a considerable amount of time looking for an intuition, idea, example to motivate discussion and the importance of random variable. Clearly it is a fundamental concept in probability but most resources focus on the formal definition, and leave a little bit aside the intuition: Why do we need this and why is it important?, At least for me, given my limitations, it was difficult to justify its role and connection beyond simply referencing the definitions "by hard".

After reading the answer of [P. Vanchinathan](https://mathoverflow.net/users/22878/p-vanchinathan) in mathoverflow on the question; ["Why do we need random variables?"](https://mathoverflow.net/a/252491) it felt like eye opening, and going back to the formal definitions in the books felt that the answer to the question "why do we need random variables?" was always in front of me, only occluded in abstraction and formulas, and that indeed "random variable" is a construct that is born naturally from the need to model a "variable" produced by a "random" process or event. 

how it connects to all this probability space machinery we have been describing, and how it interplays with the different components.

In the spirit of this note (digging into ideas and not just concepts), I must admit that after realizing the role of a random variable, I felt a sense of shame for not having recognized its importance earlier. However, this feeling was quickly overshadowed by an eye-opening sense of revelation. The goal of this section is to formally introduce the concept of a random variable, while also providing examples to build a solid and intuitive understandingâ€”and maybe, youâ€™ll experience the same aha moment.
"A random variable represents an unknown quantity (hence the term variable) that varies not as a variable in an algebraic relation (such as $x2 âˆ’ 9 = 0$), but rather varies with the outcome of a random event." @jacodProbabilityEssentials2004 chapter 5

It is hard to pinpoint a moment in history for the born of a random variable or coin the terminology to someone o some work, as it own nature seems intuitive (as you would see later), there's is no general agreement on the introduction of random variable, al thought this is not extrictly relevant for it definition it only offers a window into the history and rational behind the naming convention for this mapping random variable

[formal and general introduction measure-theoretic]

In a generic and [axiomatic](https://en.wikipedia.org/wiki/Axiomatic) setting (Measure-theoretic definition), a random variable is a **measurable map** from one measurable space to another measurable space:

<Definition term="Measurable map">
A function $X : \Omega \rightarrow \ssS$ is said to be a measurable map from $(\Omega, \ssE)$ to $(S, \ssS)$ if:
$X^{-1}(B) = \{\omega \in \Omega : X(\omega) \in S\}$
\
If $(S, \ssS) = (S^d, \ssS^d)$  and $d > 1$ then $X$ is called a **random vector**. Of course, if $d = 1$, $X$ is called a **random variable**, or $r.v.$ for short.
</Definition>

<Drawio file="probability.drawio" page="12">
    Example of random variable.
</Drawio>

<Drawio file="probability.drawio" page="13">
    Example of multiples random variable over the same sample space.
</Drawio>

<Drawio file="probability.drawio" page="14">
    Demo.
</Drawio>

General setting: 
- @durrettProbabilityTheoryExamples2019 section 1.3
- @jacodProbabilityEssentials2004 chapter 5, "a function from $\Omega$ into a set $\sT$"
- [Radom variable - Wikipedia](https://en.wikipedia.org/wiki/Random_variable#Measure-theoretic_definition)
- @calvettiIntroductionBayesianScientific2007 section 1.2


<Equation>
    $$
    X: \Omega \rightarrow \sR
    $$
    Definition of a random variable.
</Equation>


- "In this example, the identity of the box that will be chosen is a random variable, which we shall denote by B." @bishopPatternRecognitionMachine2006 section 1.2 already assume you know what a random variable is.
- "Because the values of these variables can vary from one person to another in a way that is generally unknown, they are called random variables or stochastic variables."  @bishopDeepLearningFoundations2024 section 2.1.2

Get the table comparing $r.v.$ notation with integral notation [Random Variables and Measurable Functions](http://theanalysisofdata.com/probability/2_5.html)

## Distribution

## Desity

## Law of large numbers

Chapter 2: @durrettProbabilityTheoryExamples2019, "Measure theory ends and probability begins with the definition of independence."

## Jungle of Notation

| Reference                                                        | Set | Complement | Set of sets   |
|------------------------------------------------------------------|-----|------------|---------------|
| @grinsteadGrinsteadSnellsIntroduction2009                        | $A$ | $\tilde A$ | ?             |
| @jacodProbabilityEssentials2004                                  | $A$ | $A^{c}$    | $\mathcal{A}$ |
| @jaynesProbabilityTheoryLogic2003                                | $A$ | $\bar{A}$  | $F$           |
| @rasmussenGaussianProcessesMachine2008                           | $A$ | $A^{c}$    | $\mathcal{A}$ |
| @walpoleProbabilityStatisticsEngineers2017                       | $A$ | $A'$       | $\mathcal{A}$ |
| @deisenrothMathematicsMachineLearning (chapter 6)                | $A$ | ?          | $\mathcal{A}$ |
| @bishopPatternRecognitionMachine2006 (chapter 1.2 and chapter 2) | $A$ | TBA        | TBA           |
| @bishopDeepLearningFoundations2024 (chapter 2)                   | $A$ | TBA        | TBA           |
| @goodfellowDeepLearning2016 (chapter 3)                          | $A$ | TBA        | TBA           |
 

## External Resources

- [Probability Essentials by Jean Jacod, Philip Protter](https://link.springer.com/book/10.1007/978-3-642-55682-1) chapter 2.

## References
