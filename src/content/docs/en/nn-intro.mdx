---
title: Introduction to Neural Networks
describe: Let's see inside a NN
---

export const components = {
    blockquote: Blockquote,
    a: A,
    pre: Pre,
    code: CodeBlock,
    pre: InlineCode,
    em: Em,
    h1: H1,
    h2: H2,
    h3: H3,
    h4: H4,
    h5: H5,
    h6: H6,
    hr: Hr,
    img: Img,
    ul: Ul,
    ol: Ol,
    li: Li,
    strong: Strong,
    p: P
}

## Introduction

- The brain is a highly complex, nonlinear, and parallel computer.



Build up a set of rules and behaviors through was is refer as "experience".

Neuron or processing unit: a single computing cell/unit.


> A neural network is a massively parallel distributed processor made up of simple processing units that has a natural propensity for storing experiential knowledge and making it available for use.

1. Knowledge is acquired by the network from its environment through a learning process.
2. Interneuron connection strengths, known as synaptic weights, are used to store the acquired knowledge.

learning algorithm: is the procedure of modifying the synaptic weights in order to attain a desired objective.

> Generalization refers to the neural network’s production of reasonable outputs for inputs not encountered during training (learning).


NN capabilities:
- Nonlinearity
- Input–Output Mapping
- Adaptivity
- Evidential Response
- Fault Tolerance
- VLSI Implementability (Old fashon)


Human brain:
- approximately 10 billion neurons in the human cortex, and 60 trillion synapses or connections (Shepherd and Koch, 1990).
- the energetic efficiency of the brain is approximately $10^{-16}$ joules (J)

