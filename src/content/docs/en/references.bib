@preprint{bhoiMonocularDepthEstimation2019,
  extra = {arXiv:1901.09402 [cs]},
  author = {Bhoi, Amlaan},
  abstractNote = {Monocular depth estimation is often described as an illposed and inherently ambiguous problem. Estimating depth from 2D images is a crucial step in scene reconstruction, 3D object recognition, segmentation, and detection. The problem can be framed as: given a single RGB image as input, predict a dense depth map for each pixel. This problem is worsened by the fact that most scenes have large texture and structural variations, object occlusions, and rich geometric detailing. All these factors contribute to difﬁculty in accurate depth estimation. In this paper, we review ﬁve papers that attempt to solve the depth estimation problem with various techniques including supervised, weakly-supervised, and unsupervised learning techniques. We then compare these papers and understand the improvements made over one another. Finally, we explore potential improvements that can aid to better solve this problem.},
  key = {8TVFATMW},
  libraryCatalog = {arXiv.org},
  title = {Monocular Depth Estimation: A Survey},
  year = {2019},
  language = {en},
  url = {http://arxiv.org/abs/1901.09402},
  date = {2019-01-27 2019-01-27},
  shortTitle = {Monocular Depth Estimation},
  repository = {arXiv},
  archiveID = {arXiv:1901.09402},
  accessDate = {2024-05-28 15:00:24},
}
@journalArticle{padkanEVALUATINGMONOCULARDEPTH2023,
  publicationTitle = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  journalAbbreviation = {Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.},
  abstractNote = {Depth estimation from monocular images has become a prominent focus in photogrammetry and computer vision research. Monocular Depth Estimation (MDE), which involves determining depth from a single RGB image, offers numerous advantages, including applications in simultaneous localization and mapping (SLAM), scene comprehension, 3D modeling, robotics, and autonomous driving. Depth information retrieval becomes especially crucial in situations where other sources like stereo images, optical flow, or point clouds are not available. In contrast to traditional stereo or multi-view methods, MDE techniques require fewer computational resources and smaller datasets. This research work presents a comprehensive analysis and evaluation of some state-of-the-art MDE methods, considering their ability to infer depth information in terrestrial images. The evaluation includes quantitative assessments using ground truth data, including 3D analyses and inference time.},
  ISSN = {2194-9034},
  author = {Padkan, N. and Trybala, P. and Battisti, R. and Remondino, F. and Bergeret, C.},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {137-144},
  key = {7LEQVMK2},
  title = {EVALUATING MONOCULAR DEPTH ESTIMATION METHODS},
  year = {2023},
  language = {en},
  url = {https://isprs-archives.copernicus.org/articles/XLVIII-1-W3-2023/137/2023/},
  rights = {https://creativecommons.org/licenses/by/4.0/},
  accessDate = {2024-06-27 02:01:56},
  date = {2023-10-19 2023-10-19},
  volume = {XLVIII-1/W3-2023},
  DOI = {10.5194/isprs-archives-XLVIII-1-W3-2023-137-2023},
}
@preprint{alhashimHighQualityMonocular2019,
  language = {en},
  accessDate = {2024-10-02 04:07:58},
  title = {High Quality Monocular Depth Estimation via Transfer Learning},
  extra = {arXiv:1812.11941 [cs]},
  archiveID = {arXiv:1812.11941},
  year = {2019},
  date = {2019-03-10 2019-03-10},
  url = {http://arxiv.org/abs/1812.11941},
  author = {Alhashim, Ibraheem and Wonka, Peter},
  abstractNote = {Accurate depth estimation from images is a fundamental task in many applications including scene understanding and reconstruction. Existing solutions for depth estimation often produce blurry approximations of low resolution. This paper presents a convolutional neural network for computing a high-resolution depth map given a single RGB image with the help of transfer learning. Following a standard encoder-decoder architecture, we leverage features extracted using high performing pre-trained networks when initializing our encoder along with augmentation and training strategies that lead to more accurate results. We show how, even for a very simple decoder, our method is able to achieve detailed high-resolution depth maps. Our network, with fewer parameters and training iterations, outperforms state-of-the-art on two datasets and also produces qualitatively better results that capture object boundaries more faithfully. Code and corresponding pre-trained weights are made publicly available1.},
  libraryCatalog = {arXiv.org},
  repository = {arXiv},
  key = {32BVAV9H},
}
@conferencePaper{BlochLaurent2015,
  title = {Informatics in the light of some Leibniz’s works},
  year = {2016},
  date = {2016-05-00 2016-05},
  author = {Bloch, Laurent},
  key = {3YCK8RDT},
  extra = {Citation Key: BlochLaurent2015},
}
@preprint{tzesGraphNeuralNetworks2022,
  title = {Graph Neural Networks for Multi-Robot Active Information Acquisition},
  abstractNote = {This paper addresses the Multi-Robot Active Information Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph representation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot conﬁgurations. Experiments on signiﬁcantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efﬁcacy in the application of localization and tracking of dynamic targets.},
  archiveID = {arXiv:2209.12091},
  key = {UETYTIWH},
  extra = {arXiv:2209.12091 [cs]},
  year = {2022},
  url = {http://arxiv.org/abs/2209.12091},
  repository = {arXiv},
  language = {en},
  accessDate = {2023-08-15 11:31:30},
  author = {Tzes, Mariliza and Bousias, Nikolaos and Chatzipantazis, Evangelos and Pappas, George J.},
  libraryCatalog = {arXiv.org},
  date = {2022-09-24 2022-09-24},
}
@preprint{bochkovskiiDepthProSharp2024,
  language = {en},
  accessDate = {2024-11-11 15:51:14},
  author = {Bochkovskii, Aleksei and Delaunoy, Amaël and Germain, Hugo and Santos, Marcel and Zhou, Yichao and Richter, Stephan R. and Koltun, Vladlen},
  repository = {arXiv},
  extra = {arXiv:2410.02073 [cs]},
  abstractNote = {We present a foundation model for zero-shot metric monocular depth estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with unparalleled sharpness and high-frequency details. The predictions are metric, with absolute scale, without relying on the availability of metadata such as camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map in 0.3 seconds on a standard GPU. These characteristics are enabled by a number of technical contributions, including an efficient multi-scale vision transformer for dense prediction, a training protocol that combines real and synthetic datasets to achieve high metric accuracy alongside fine boundary tracing, dedicated evaluation metrics for boundary accuracy in estimated depth maps, and state-of-the-art focal length estimation from a single image. Extensive experiments analyze specific design choices and demonstrate that Depth Pro outperforms prior work along multiple dimensions. We release code and weights at https://github.com/apple/ml-depth-pro},
  title = {Depth Pro: Sharp Monocular Metric Depth in Less Than a Second},
  libraryCatalog = {arXiv.org},
  url = {http://arxiv.org/abs/2410.02073},
  shortTitle = {Depth Pro},
  key = {JJ5C6VKZ},
  date = {2024-10-02 2024-10-02},
  year = {2024},
  archiveID = {arXiv:2410.02073},
}
@preprint{eigenDepthMapPrediction2014,
  year = {2014},
  archiveID = {arXiv:1406.2283},
  title = {Depth Map Prediction from a Single Image using a Multi-Scale Deep Network},
  author = {Eigen, David and Puhrsch, Christian and Fergus, Rob},
  abstractNote = {Predicting depth is an essential component in understanding the 3D geometry of a scene. While for stereo images local correspondence sufﬁces for estimation, ﬁnding depth relations from a single image is less straightforward, requiring integration of both global and local information from various cues. Moreover, the task is inherently ambiguous, with a large source of uncertainty coming from the overall scale. In this paper, we present a new method that addresses this task by employing two deep network stacks: one that makes a coarse global prediction based on the entire image, and another that reﬁnes this prediction locally. We also apply a scale-invariant error to help measure depth relations rather than scale. By leveraging the raw datasets as large sources of training data, our method achieves state-of-the-art results on both NYU Depth and KITTI, and matches detailed depth boundaries without the need for superpixelation.},
  libraryCatalog = {arXiv.org},
  extra = {arXiv:1406.2283 [cs]},
  key = {TCZ78FYN},
  repository = {arXiv},
  accessDate = {2023-08-10 12:19:39},
  language = {en},
  url = {http://arxiv.org/abs/1406.2283},
  date = {2014-06-09 2014-06-09},
}
@journalArticle{zhaoMonocularDepthEstimation2020,
  libraryCatalog = {arXiv.org},
  pages = {1612-1627},
  author = {Zhao, Chaoqiang and Sun, Qiyu and Zhang, Chongzhen and Tang, Yang and Qian, Feng},
  extra = {arXiv:2003.06620 [cs]},
  url = {http://arxiv.org/abs/2003.06620},
  publicationTitle = {Science China Technological Sciences},
  language = {en},
  abstractNote = {Depth information is important for autonomous systems to perceive environments and estimate their own state. Traditional depth estimation methods, like structure from motion and stereo vision matching, are built on feature correspondences of multiple viewpoints. Meanwhile, the predicted depth maps are sparse. Inferring depth information from a single image (monocular depth estimation) is an ill-posed problem. With the rapid development of deep neural networks, monocular depth estimation based on deep learning has been widely studied recently and achieved promising performance in accuracy. Meanwhile, dense depth maps are estimated from single images by deep neural networks in an end-to-end manner. In order to improve the accuracy of depth estimation, different kinds of network frameworks, loss functions and training strategies are proposed subsequently. Therefore, we survey the current monocular depth estimation methods based on deep learning in this review. Initially, we conclude several widely used datasets and evaluation indicators in deep learning-based depth estimation. Furthermore, we review some representative existing methods according to different training manners: supervised, unsupervised and semisupervised. Finally, we discuss the challenges and provide some ideas for future researches in monocular depth estimation.},
  accessDate = {2024-06-14 06:36:43},
  ISSN = {1674-7321, 1869-1900},
  volume = {63},
  journalAbbreviation = {Sci. China Technol. Sci.},
  key = {5IWGDN7U},
  date = {2020-09-00 09-2020},
  DOI = {10.1007/s11431-020-1582-8},
  issue = {9},
  title = {Monocular Depth Estimation Based On Deep Learning: An Overview},
  year = {2020},
  shortTitle = {Monocular Depth Estimation Based On Deep Learning},
}
@conferencePaper{vandijkHowNeuralNetworks2019,
  rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  author = {Van Dijk, Tom and De Croon, Guido},
  conferenceName = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  ISBN = {978-1-7281-4803-8},
  abstractNote = {Deep neural networks have lead to a breakthrough in depth estimation from single images. Recent work shows that the quality of these estimations is rapidly increasing. It is clear that neural networks can see depth in single images. However, to the best of our knowledge, no work currently exists that analyzes what these networks have learned.},
  url = {https://ieeexplore.ieee.org/document/9009532/},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {2183-2191},
  proceedingsTitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  language = {en},
  place = {Seoul, Korea (South)},
  date = {2019-10-00 2010-10-00},
  key = {XMZVKHSM},
  title = {How Do Neural Networks See Depth in Single Images?},
  publisher = {IEEE},
  DOI = {10.1109/ICCV.2019.00227},
  year = {2019},
  accessDate = {2025-01-04 22:19:24},
}
@journalArticle{khaldiOverviewSwarmRobotics2015,
  date = {2015-09-17 2015-09-17},
  publicationTitle = {International Journal of Computer Applications},
  issue = {2},
  journalAbbreviation = {IJCA},
  author = {Khaldi, Belkacem and Cherif, Foudil},
  language = {en},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {31-37},
  url = {http://www.ijcaonline.org/research/volume126/number2/khaldi-2015-ijca-906000.pdf},
  key = {N2A9WKS6},
  year = {2015},
  abstractNote = {As an emergent research area by which swarm intelligence is applied to multi-robot systems; swarm robotics (a very particular and peculiar sub-area of collective robotics) studies how to coordinate large groups of relatively simple robots through the use of local rules. It focuses on studying the design of large amount of relatively simple robots, their physical bodies and their controlling behaviors. Since its introduction in 2000, several successful experimentations had been realized, and till now more projects are under investigations. This paper seeks to give an overview of this domain research; for the aim to orientate the readers, especially those who are newly coming to this research field.},
  ISSN = {09758887},
  DOI = {10.5120/ijca2015906000},
  title = {An Overview of Swarm Robotics: Swarm Intelligence Applied to Multi-robotics},
  shortTitle = {An Overview of Swarm Robotics},
  accessDate = {2025-02-03 15:31:06},
  volume = {126},
}
@journalArticle{saxenaLearningDepthSingle,
  key = {J3QQAXIN},
  title = {Learning Depth from Single Monocular Images},
  year = {NA},
  abstractNote = {We consider the task of depth estimation from a single monocular image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufﬁcient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a discriminatively-trained Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models both depths at individual points as well as the relation between depths at different points. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps.},
  author = {Saxena, Ashutosh and Chung, Sung H and Ng, Andrew Y},
  language = {en},
  libraryCatalog = {Zotero},
}
@journalArticle{tanSwarmRoboticsCollective2013,
  key = {GLFLXVWD},
  title = {Swarm Robotics: Collective Behavior Inspired by Nature},
  url = {https://www.hilarispublisher.com/open-access/swarm-robotics-collective-behavior-inspired-by-nature-jcsb.1000e106.pdf},
  DOI = {10.4172/jcsb.1000e106},
  volume = {6},
  year = {2013},
  ISSN = {0974-7230},
  publicationTitle = {Journal of Computer Science & Systems Biology},
  date = {2013-00-00 2013},
  author = {Tan, Ying},
  language = {en},
  libraryCatalog = {Zotero},
}
@journalArticle{sharkeySwarmRoboticsMinimalism2007,
  key = {7U4USFRL},
  title = {Swarm robotics and minimalism},
  DOI = {10.1080/09540090701584970},
  year = {2007},
  pages = {245-260},
  issue = {3},
  libraryCatalog = {DOI.org (Crossref)},
  date = {2007-09-00 2007-09},
  url = {https://www.tandfonline.com/doi/full/10.1080/09540090701584970},
  journalAbbreviation = {Connection Science},
  volume = {19},
  author = {Sharkey, Amanda J. C.},
  language = {en},
  ISSN = {0954-0091, 1360-0494},
  publicationTitle = {Connection Science},
  accessDate = {2025-02-04 02:13:30},
}
@bookSection{beniSwarmIntelligenceCellular1993,
  key = {22EJZYDL},
  title = {Swarm Intelligence in Cellular Robotic Systems},
  extra = {DOI: 10.1007/978-3-642-58069-7_38},
  place = {Berlin, Heidelberg},
  year = {1993},
  pages = {703-712},
  abstractNote = {Cellular Robotic Systems are capable of 'intelligent' behavior. The meaning of this intelligence is analyzed in the paper. We define robot intelligence and robot system intelligence in terms of unpredictability of improbable behavior. The concept of unpredictability is analyzed in relation to (1) statistical unpredictability, (2) inaccessibility, (3) undecidability, (4) intractability, and (5) non-representability. We argue that the latter two type of unpredictability, when exhibited by systems capable of producing order, can result in a non-trivial, different form of intelligent behavior (Swarm Intelligence). Engineering problems related to Swarm Intelligence are mentioned in relation to Cellular Robotic Systems which consist of collections of autonomous, non-synchronized, non-. intelligent robots cooperating to achieve global tasks.},
  publisher = {Springer Berlin Heidelberg},
  rights = {http://www.springer.com/tdm},
  libraryCatalog = {DOI.org (Crossref)},
  date = {1993-00-00 1993},
  url = {http://link.springer.com/10.1007/978-3-642-58069-7_38},
  bookTitle = {Robots and Biological Systems: Towards a New Bionics?},
  author = {Dario, Paolo and Sandini, Giulio and Aebischer, Patrick and Beni, Gerardo and Wang, Jing},
  ISBN = {978-3-642-63461-1 978-3-642-58069-7},
  language = {en},
  accessDate = {2025-02-04 02:24:35},
}
@thesis{ferranteControlArchitectureHeterogeneous2009,
  key = {YR4DAQKC},
  title = {A Control Architecture for a Heterogeneous Swarm of Robots},
  url = {https://iridia.ulb.ac.be/~mdorigo/HomePageDorigo/thesis/dea/FerranteMAS.pdf},
  year = {2009},
  thesisType = {PhD Thesis},
  date = {2009-00-00 2009},
  university = {UNIVERSIT ´E LIBRE DE BRUXELLES},
  abstractNote = {We propose a software architecture that can ease and speed up the development process of controllers for heterogeneous swarm systems. It is inherently modular and allows behaviors to be combined in layers and reused in multiple controllers. This can potentially speedup the development process of controllers since they become much more readable and well structured. We validated the architecture through an experiment of collective navigation and obstacle avoidance using two different types of robots. The experiments show that, using the proposed architecture, complex behaviors can indeed be built through the combination of very simple behaviors.},
  author = {Ferrante, Eliseo},
  language = {en},
  libraryCatalog = {Zotero},
}
@bookSection{yangSwarmBasedMetaheuristicAlgorithms2012,
  year = {2012},
  key = {XQTTDU6G},
  title = {Swarm-Based Metaheuristic Algorithms and No-Free-Lunch Theorems},
  url = {http://www.intechopen.com/books/theory-and-new-applications-of-swarm-intelligence/swarm-based-metaheuristic-algorithms-and-no-free-lunch-theorems},
  bookTitle = {Theory and New Applications of Swarm Intelligence},
  ISBN = {978-953-51-0364-6},
  publisher = {InTech},
  extra = {DOI: 10.5772/30852},
  date = {2012-03-16 2012-03-16},
  author = {Parpinelli, Rafael and Yang, Xin-She},
  language = {en},
  libraryCatalog = {DOI.org (Crossref)},
  accessDate = {2025-02-04 16:13:53},
}
@journalArticle{neshatArtificialFishSwarm2014,
  key = {KT57PTXC},
  title = {Artificial fish swarm algorithm: a survey of the state-of-the-art, hybridization, combinatorial and indicative applications},
  DOI = {10.1007/s10462-012-9342-2},
  year = {2014},
  pages = {965-997},
  abstractNote = {AFSA (artiﬁcial ﬁsh-swarm algorithm) is one of the best methods of optimization among the swarm intelligence algorithms. This algorithm is inspired by the collective movement of the ﬁsh and their various social behaviors. Based on a series of instinctive behaviors, the ﬁsh always try to maintain their colonies and accordingly demonstrate intelligent behaviors. Searching for food, immigration and dealing with dangers all happen in a social form and interactions between all ﬁsh in a group will result in an intelligent social behavior. This algorithm has many advantages including high convergence speed, ﬂexibility, fault tolerance and high accuracy. This paper is a review of AFSA algorithm and describes the evolution of this algorithm along with all improvements, its combination with various methods as well as its applications. There are many optimization methods which have a afﬁnity with this method and the result of this combination will improve the performance of this method. Its disadvantages include high time complexity, lack of balance between global and local search, in addition to lack of beneﬁting from the experiences of group members for the next movements.},
  issue = {4},
  rights = {http://www.springer.com/tdm},
  libraryCatalog = {DOI.org (Crossref)},
  date = {2014-12-00 2014-12},
  url = {http://link.springer.com/10.1007/s10462-012-9342-2},
  shortTitle = {Artificial fish swarm algorithm},
  journalAbbreviation = {Artif Intell Rev},
  publicationTitle = {Artificial Intelligence Review},
  author = {Neshat, Mehdi and Sepidnam, Ghodrat and Sargolzaei, Mehdi and Toosi, Adel Najaran},
  language = {en},
  ISSN = {0269-2821, 1573-7462},
  volume = {42},
  accessDate = {2025-02-04 16:17:54},
}
@journalArticle{hamdiBeebasedAlgorithmsReview2010,
  year = {2010},
  date = {2010-10-00 10-2010},
  language = {en},
  libraryCatalog = {Zotero},
  pages = {2},
  title = {Bee-based algorithms: a review},
  key = {UA542PLJ},
  author = {Hamdi, A and Monmarché, N and Alimi, M Adel and Slimane, M},
  url = {https://www.researchgate.net/profile/Amira-Hamdi/publication/237844606_META10_Bee-based_algorithms_a_review_META_2010/links/0046351be9feb2e247000000/META10-Bee-based-algorithms-a-review-META-2010.pdf},
}
@book{sahinSwarmRoboticsSAB2005,
  seriesNumber = {3342},
  author = {Şahin, Erol and Spears, William M.},
  series = {Lecture notes in computer science, State-of-the-art survey},
  publisher = {Springer},
  ISBN = {978-3-540-24296-3},
  shortTitle = {Swarm robotics},
  language = {en},
  libraryCatalog = {Library of Congress ISBN},
  year = {2005},
  numPages = {174},
  key = {HNUULXXY},
  extra = {Meeting Name: International Conference on Simulation of Adaptive Behavior
OCLC: ocm57597119},
  callNumber = {TJ210.3 .I633 2004},
  date = {2005-00-00 2005},
  place = {Berlin ; New York},
  title = {Swarm robotics: SAB 2004 international workshop, Santa Monica, CA, USA, July 17, 2004: revised selected papers},
}
@journalArticle{dorigoEvolvingSelfOrganizingBehaviors2004,
  url = {http://link.springer.com/10.1023/B:AURO.0000033973.24945.f3},
  author = {Dorigo, Marco and Trianni, Vito and Şahin, Erol and Groß, Roderich and Labella, Thomas H. and Baldassarre, Gianluca and Nolfi, Stefano and Deneubourg, Jean-Louis and Mondada, Francesco and Floreano, Dario and Gambardella, Luca M.},
  accessDate = {2025-02-04 20:55:06},
  key = {XDTAB9H8},
  volume = {17},
  publicationTitle = {Autonomous Robots},
  issue = {2/3},
  ISSN = {0929-5593},
  language = {en},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {223-245},
  DOI = {10.1023/B:AURO.0000033973.24945.f3},
  abstractNote = {In this paper, we introduce a self-assembling and self-organizing artifact, called a swarm-bot, composed of a swarm of s-bots, mobile robots with the ability to connect to and to disconnect from each other. We discuss the challenges involved in controlling a swarm-bot and address the problem of synthesizing controllers for the swarm-bot using artiﬁcial evolution. Speciﬁcally, we study aggregation and coordinated motion of the swarm-bot using a physics-based simulation of the system. Experiments, using a simpliﬁed simulation model of the s-bots, show that evolution can discover simple but eﬀective controllers for both the aggregation and the coordinated motion of the swarm-bot. Analysis of the evolved controllers shows that they have properties of scalability, that is, they continue to be eﬀective for larger group sizes, and of generality, that is, they produce similar behaviors for conﬁgurations diﬀerent from those they were originally evolved for. The portability of the evolved controllers to real s-bots is tested using a detailed simulation model which has been validated against the real s-bots in a companion paper in this same special issue.},
  year = {2004},
  date = {2004-09-00 2004-09},
  journalAbbreviation = {Autonomous Robots},
  title = {Evolving Self-Organizing Behaviors for a Swarm-Bot},
}
@journalArticle{dorigoGuestEditorial2004,
  url = {http://link.springer.com/10.1023/B:AURO.0000034008.48988.2b},
  author = {Dorigo, Marco and Şahin, Erol},
  accessDate = {2025-02-04 21:42:39},
  key = {3KCSR9D7},
  volume = {17},
  publicationTitle = {Autonomous Robots},
  issue = {2/3},
  ISSN = {0929-5593},
  language = {en},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {111-113},
  DOI = {10.1023/B:AURO.0000034008.48988.2b},
  year = {2004},
  date = {2004-09-00 2004-09},
  journalAbbreviation = {Autonomous Robots},
  title = {Guest Editorial},
}
@conferencePaper{carpinUSARSimRobotSimulator2007,
  url = {http://ieeexplore.ieee.org/document/4209284/},
  proceedingsTitle = {Proceedings 2007 IEEE International Conference on Robotics and Automation},
  author = {Carpin, Stefano and Lewis, Mike and Wang, Jijun and Balakirsky, Stephen and Scrapper, Chris},
  conferenceName = {2007 IEEE International Conference on Robotics and Automation},
  publisher = {IEEE},
  accessDate = {2025-02-04 23:33:50},
  ISBN = {978-1-4244-0602-9 978-1-4244-0601-2},
  shortTitle = {USARSim},
  extra = {ISSN: 1050-4729},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {1400-1405},
  date = {2007-04-00 2007-04},
  language = {en},
  DOI = {10.1109/ROBOT.2007.363180},
  abstractNote = {This paper presents USARSim, an open source high ﬁdelity robot simulator that can be used both for research and education. USARSim offers many characteristics that differentiates it from most existing simulators. Most notably, it constitutes the simulation engine used to run the Virtual Robots Competition within the Robocup initiative. We describe its general architecture, describe examples of utilization, and provide a comprehensive overview for those interested in robot simulations for education, research and competitions.},
  year = {2007},
  key = {BS56UZQR},
  place = {Rome, Italy},
  title = {USARSim: a robot simulator for research and education},
}
@preprint{dimmigSurveySimulatorsAerial2023,
  url = {http://arxiv.org/abs/2311.02296},
  archiveID = {arXiv:2311.02296},
  extra = {arXiv:2311.02296 [cs]},
  libraryCatalog = {arXiv.org},
  author = {Dimmig, Cora A. and Silano, Giuseppe and McGuire, Kimberly and Gabellieri, Chiara and Hönig, Wolfgang and Moore, Joseph and Kobilarov, Marin},
  accessDate = {2023-11-09 14:48:21},
  language = {en},
  abstractNote = {Uncrewed Aerial Vehicle (UAV) research faces challenges with safety, scalability, costs, and ecological impact when conducting hardware testing. High-ﬁdelity simulators offer a vital solution by replicating real-world conditions to enable the development and evaluation of novel perception and control algorithms. However, the large number of available simulators poses a signiﬁcant challenge for researchers to determine which simulator best suits their speciﬁc use-case, based on each simulator’s limitations and customization readiness. This paper analyzes existing UAV simulators and decision factors for their selection, aiming to enhance the efﬁciency and safety of research endeavors.},
  repository = {arXiv},
  year = {2023},
  key = {RHBGCFVW},
  date = {2023-11-03 2023-11-03},
  title = {Survey of Simulators for Aerial Robots},
}
@bookSection{lacheleSwarmSimXRealTimeSimulation2012,
  url = {http://link.springer.com/10.1007/978-3-642-34327-8_34},
  date = {2012-00-00 2012},
  publisher = {Springer Berlin Heidelberg},
  accessDate = {2025-02-05 00:00:33},
  ISBN = {978-3-642-34326-1 978-3-642-34327-8},
  volume = {7628},
  shortTitle = {SwarmSimX},
  extra = {Series Title: Lecture Notes in Computer Science
DOI: 10.1007/978-3-642-34327-8_34},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {375-387},
  author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Noda, Itsuki and Ando, Noriaki and Brugali, Davide and Kuffner, James J. and Lächele, Johannes and Franchi, Antonio and Bülthoff, Heinrich H. and Robuffo Giordano, Paolo},
  language = {en},
  abstractNote = {In this paper we present a novel simulation environment called SwarmSimX with the ability to simulate dozens of robots in a realistic 3D environment. The software architecture of SwarmSimX allows new robots, sensors, and other libraries to be loaded at runtime, extending the functionality of the simulation environment signiﬁcantly. In addition, SwarmSimX allows an easy exchange of the underlying libraries used for the visual and physical simulation to incorporate diﬀerent libraries (e.g., improved or future versions). A major feature is also the possibility to perform the whole simulation in real-time allowing for human-in-the-loop or hardware-in-the-loop scenarios. SwarmSimX has been already employed in several works presenting haptic shared control of multiple mobile robots (e.g., quadrotor UAVs). Additionally, we present here two validation tests showing the physical ﬁdelity and the real-time performance of SwarmSimX. For the tests we used NVIDIA R © PhysX© R and Ogre3D as physics and rendering libraries, respectively.},
  bookTitle = {Simulation, Modeling, and Programming for Autonomous Robots},
  year = {2012},
  key = {967BBGIU},
  place = {Berlin, Heidelberg},
  title = {SwarmSimX: Real-Time Simulation Environment for Multi-robot Systems},
}
