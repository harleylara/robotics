@preprint{bhoiMonocularDepthEstimation2019,
  extra = {arXiv:1901.09402 [cs]},
  author = {Bhoi, Amlaan},
  abstractNote = {Monocular depth estimation is often described as an illposed and inherently ambiguous problem. Estimating depth from 2D images is a crucial step in scene reconstruction, 3D object recognition, segmentation, and detection. The problem can be framed as: given a single RGB image as input, predict a dense depth map for each pixel. This problem is worsened by the fact that most scenes have large texture and structural variations, object occlusions, and rich geometric detailing. All these factors contribute to difﬁculty in accurate depth estimation. In this paper, we review ﬁve papers that attempt to solve the depth estimation problem with various techniques including supervised, weakly-supervised, and unsupervised learning techniques. We then compare these papers and understand the improvements made over one another. Finally, we explore potential improvements that can aid to better solve this problem.},
  key = {8TVFATMW},
  libraryCatalog = {arXiv.org},
  title = {Monocular Depth Estimation: A Survey},
  year = {2019},
  language = {en},
  url = {http://arxiv.org/abs/1901.09402},
  date = {2019-01-27 2019-01-27},
  shortTitle = {Monocular Depth Estimation},
  repository = {arXiv},
  archiveID = {arXiv:1901.09402},
  accessDate = {2024-05-28 15:00:24},
}
@journalArticle{padkanEVALUATINGMONOCULARDEPTH2023,
  publicationTitle = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  journalAbbreviation = {Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.},
  abstractNote = {Depth estimation from monocular images has become a prominent focus in photogrammetry and computer vision research. Monocular Depth Estimation (MDE), which involves determining depth from a single RGB image, offers numerous advantages, including applications in simultaneous localization and mapping (SLAM), scene comprehension, 3D modeling, robotics, and autonomous driving. Depth information retrieval becomes especially crucial in situations where other sources like stereo images, optical flow, or point clouds are not available. In contrast to traditional stereo or multi-view methods, MDE techniques require fewer computational resources and smaller datasets. This research work presents a comprehensive analysis and evaluation of some state-of-the-art MDE methods, considering their ability to infer depth information in terrestrial images. The evaluation includes quantitative assessments using ground truth data, including 3D analyses and inference time.},
  ISSN = {2194-9034},
  author = {Padkan, N. and Trybala, P. and Battisti, R. and Remondino, F. and Bergeret, C.},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {137-144},
  key = {7LEQVMK2},
  title = {EVALUATING MONOCULAR DEPTH ESTIMATION METHODS},
  year = {2023},
  language = {en},
  url = {https://isprs-archives.copernicus.org/articles/XLVIII-1-W3-2023/137/2023/},
  rights = {https://creativecommons.org/licenses/by/4.0/},
  accessDate = {2024-06-27 02:01:56},
  date = {2023-10-19 2023-10-19},
  volume = {XLVIII-1/W3-2023},
  DOI = {10.5194/isprs-archives-XLVIII-1-W3-2023-137-2023},
}
@preprint{alhashimHighQualityMonocular2019,
  language = {en},
  accessDate = {2024-10-02 04:07:58},
  title = {High Quality Monocular Depth Estimation via Transfer Learning},
  extra = {arXiv:1812.11941 [cs]},
  archiveID = {arXiv:1812.11941},
  year = {2019},
  date = {2019-03-10 2019-03-10},
  url = {http://arxiv.org/abs/1812.11941},
  author = {Alhashim, Ibraheem and Wonka, Peter},
  abstractNote = {Accurate depth estimation from images is a fundamental task in many applications including scene understanding and reconstruction. Existing solutions for depth estimation often produce blurry approximations of low resolution. This paper presents a convolutional neural network for computing a high-resolution depth map given a single RGB image with the help of transfer learning. Following a standard encoder-decoder architecture, we leverage features extracted using high performing pre-trained networks when initializing our encoder along with augmentation and training strategies that lead to more accurate results. We show how, even for a very simple decoder, our method is able to achieve detailed high-resolution depth maps. Our network, with fewer parameters and training iterations, outperforms state-of-the-art on two datasets and also produces qualitatively better results that capture object boundaries more faithfully. Code and corresponding pre-trained weights are made publicly available1.},
  libraryCatalog = {arXiv.org},
  repository = {arXiv},
  key = {32BVAV9H},
}
@conferencePaper{BlochLaurent2015,
  title = {Informatics in the light of some Leibniz’s works},
  year = {2016},
  date = {2016-05-00 2016-05},
  author = {Bloch, Laurent},
  key = {3YCK8RDT},
  extra = {Citation Key: BlochLaurent2015},
}
@preprint{tzesGraphNeuralNetworks2022,
  title = {Graph Neural Networks for Multi-Robot Active Information Acquisition},
  abstractNote = {This paper addresses the Multi-Robot Active Information Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph representation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot conﬁgurations. Experiments on signiﬁcantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efﬁcacy in the application of localization and tracking of dynamic targets.},
  archiveID = {arXiv:2209.12091},
  key = {UETYTIWH},
  extra = {arXiv:2209.12091 [cs]},
  year = {2022},
  url = {http://arxiv.org/abs/2209.12091},
  repository = {arXiv},
  language = {en},
  accessDate = {2023-08-15 11:31:30},
  author = {Tzes, Mariliza and Bousias, Nikolaos and Chatzipantazis, Evangelos and Pappas, George J.},
  libraryCatalog = {arXiv.org},
  date = {2022-09-24 2022-09-24},
}
