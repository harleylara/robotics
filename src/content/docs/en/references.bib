@preprint{bhoiMonocularDepthEstimation2019,
  extra = {arXiv:1901.09402 [cs]},
  author = {Bhoi, Amlaan},
  abstractNote = {Monocular depth estimation is often described as an illposed and inherently ambiguous problem. Estimating depth from 2D images is a crucial step in scene reconstruction, 3D object recognition, segmentation, and detection. The problem can be framed as: given a single RGB image as input, predict a dense depth map for each pixel. This problem is worsened by the fact that most scenes have large texture and structural variations, object occlusions, and rich geometric detailing. All these factors contribute to difﬁculty in accurate depth estimation. In this paper, we review ﬁve papers that attempt to solve the depth estimation problem with various techniques including supervised, weakly-supervised, and unsupervised learning techniques. We then compare these papers and understand the improvements made over one another. Finally, we explore potential improvements that can aid to better solve this problem.},
  key = {8TVFATMW},
  libraryCatalog = {arXiv.org},
  title = {Monocular Depth Estimation: A Survey},
  year = {2019},
  language = {en},
  url = {http://arxiv.org/abs/1901.09402},
  date = {2019-01-27 2019-01-27},
  shortTitle = {Monocular Depth Estimation},
  repository = {arXiv},
  archiveID = {arXiv:1901.09402},
  accessDate = {2024-05-28 15:00:24},
}
@journalArticle{padkanEVALUATINGMONOCULARDEPTH2023,
  publicationTitle = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  journalAbbreviation = {Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.},
  abstractNote = {Depth estimation from monocular images has become a prominent focus in photogrammetry and computer vision research. Monocular Depth Estimation (MDE), which involves determining depth from a single RGB image, offers numerous advantages, including applications in simultaneous localization and mapping (SLAM), scene comprehension, 3D modeling, robotics, and autonomous driving. Depth information retrieval becomes especially crucial in situations where other sources like stereo images, optical flow, or point clouds are not available. In contrast to traditional stereo or multi-view methods, MDE techniques require fewer computational resources and smaller datasets. This research work presents a comprehensive analysis and evaluation of some state-of-the-art MDE methods, considering their ability to infer depth information in terrestrial images. The evaluation includes quantitative assessments using ground truth data, including 3D analyses and inference time.},
  ISSN = {2194-9034},
  author = {Padkan, N. and Trybala, P. and Battisti, R. and Remondino, F. and Bergeret, C.},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {137-144},
  key = {7LEQVMK2},
  title = {EVALUATING MONOCULAR DEPTH ESTIMATION METHODS},
  year = {2023},
  language = {en},
  url = {https://isprs-archives.copernicus.org/articles/XLVIII-1-W3-2023/137/2023/},
  rights = {https://creativecommons.org/licenses/by/4.0/},
  accessDate = {2024-06-27 02:01:56},
  date = {2023-10-19 2023-10-19},
  volume = {XLVIII-1/W3-2023},
  DOI = {10.5194/isprs-archives-XLVIII-1-W3-2023-137-2023},
}
@preprint{alhashimHighQualityMonocular2019,
  language = {en},
  accessDate = {2024-10-02 04:07:58},
  title = {High Quality Monocular Depth Estimation via Transfer Learning},
  extra = {arXiv:1812.11941 [cs]},
  archiveID = {arXiv:1812.11941},
  year = {2019},
  date = {2019-03-10 2019-03-10},
  url = {http://arxiv.org/abs/1812.11941},
  author = {Alhashim, Ibraheem and Wonka, Peter},
  abstractNote = {Accurate depth estimation from images is a fundamental task in many applications including scene understanding and reconstruction. Existing solutions for depth estimation often produce blurry approximations of low resolution. This paper presents a convolutional neural network for computing a high-resolution depth map given a single RGB image with the help of transfer learning. Following a standard encoder-decoder architecture, we leverage features extracted using high performing pre-trained networks when initializing our encoder along with augmentation and training strategies that lead to more accurate results. We show how, even for a very simple decoder, our method is able to achieve detailed high-resolution depth maps. Our network, with fewer parameters and training iterations, outperforms state-of-the-art on two datasets and also produces qualitatively better results that capture object boundaries more faithfully. Code and corresponding pre-trained weights are made publicly available1.},
  libraryCatalog = {arXiv.org},
  repository = {arXiv},
  key = {32BVAV9H},
}
@conferencePaper{BlochLaurent2015,
  title = {Informatics in the light of some Leibniz’s works},
  year = {2016},
  date = {2016-05-00 2016-05},
  author = {Bloch, Laurent},
  key = {3YCK8RDT},
  extra = {Citation Key: BlochLaurent2015},
}
@preprint{tzesGraphNeuralNetworks2022,
  title = {Graph Neural Networks for Multi-Robot Active Information Acquisition},
  abstractNote = {This paper addresses the Multi-Robot Active Information Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph representation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot conﬁgurations. Experiments on signiﬁcantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efﬁcacy in the application of localization and tracking of dynamic targets.},
  archiveID = {arXiv:2209.12091},
  key = {UETYTIWH},
  extra = {arXiv:2209.12091 [cs]},
  year = {2022},
  url = {http://arxiv.org/abs/2209.12091},
  repository = {arXiv},
  language = {en},
  accessDate = {2023-08-15 11:31:30},
  author = {Tzes, Mariliza and Bousias, Nikolaos and Chatzipantazis, Evangelos and Pappas, George J.},
  libraryCatalog = {arXiv.org},
  date = {2022-09-24 2022-09-24},
}
@preprint{bochkovskiiDepthProSharp2024,
  language = {en},
  accessDate = {2024-11-11 15:51:14},
  author = {Bochkovskii, Aleksei and Delaunoy, Amaël and Germain, Hugo and Santos, Marcel and Zhou, Yichao and Richter, Stephan R. and Koltun, Vladlen},
  repository = {arXiv},
  extra = {arXiv:2410.02073 [cs]},
  abstractNote = {We present a foundation model for zero-shot metric monocular depth estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with unparalleled sharpness and high-frequency details. The predictions are metric, with absolute scale, without relying on the availability of metadata such as camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map in 0.3 seconds on a standard GPU. These characteristics are enabled by a number of technical contributions, including an efficient multi-scale vision transformer for dense prediction, a training protocol that combines real and synthetic datasets to achieve high metric accuracy alongside fine boundary tracing, dedicated evaluation metrics for boundary accuracy in estimated depth maps, and state-of-the-art focal length estimation from a single image. Extensive experiments analyze specific design choices and demonstrate that Depth Pro outperforms prior work along multiple dimensions. We release code and weights at https://github.com/apple/ml-depth-pro},
  title = {Depth Pro: Sharp Monocular Metric Depth in Less Than a Second},
  libraryCatalog = {arXiv.org},
  url = {http://arxiv.org/abs/2410.02073},
  shortTitle = {Depth Pro},
  key = {JJ5C6VKZ},
  date = {2024-10-02 2024-10-02},
  year = {2024},
  archiveID = {arXiv:2410.02073},
}
@preprint{eigenDepthMapPrediction2014,
  year = {2014},
  archiveID = {arXiv:1406.2283},
  title = {Depth Map Prediction from a Single Image using a Multi-Scale Deep Network},
  author = {Eigen, David and Puhrsch, Christian and Fergus, Rob},
  abstractNote = {Predicting depth is an essential component in understanding the 3D geometry of a scene. While for stereo images local correspondence sufﬁces for estimation, ﬁnding depth relations from a single image is less straightforward, requiring integration of both global and local information from various cues. Moreover, the task is inherently ambiguous, with a large source of uncertainty coming from the overall scale. In this paper, we present a new method that addresses this task by employing two deep network stacks: one that makes a coarse global prediction based on the entire image, and another that reﬁnes this prediction locally. We also apply a scale-invariant error to help measure depth relations rather than scale. By leveraging the raw datasets as large sources of training data, our method achieves state-of-the-art results on both NYU Depth and KITTI, and matches detailed depth boundaries without the need for superpixelation.},
  libraryCatalog = {arXiv.org},
  extra = {arXiv:1406.2283 [cs]},
  key = {TCZ78FYN},
  repository = {arXiv},
  accessDate = {2023-08-10 12:19:39},
  language = {en},
  url = {http://arxiv.org/abs/1406.2283},
  date = {2014-06-09 2014-06-09},
}
@journalArticle{zhaoMonocularDepthEstimation2020,
  libraryCatalog = {arXiv.org},
  pages = {1612-1627},
  author = {Zhao, Chaoqiang and Sun, Qiyu and Zhang, Chongzhen and Tang, Yang and Qian, Feng},
  extra = {arXiv:2003.06620 [cs]},
  url = {http://arxiv.org/abs/2003.06620},
  publicationTitle = {Science China Technological Sciences},
  language = {en},
  abstractNote = {Depth information is important for autonomous systems to perceive environments and estimate their own state. Traditional depth estimation methods, like structure from motion and stereo vision matching, are built on feature correspondences of multiple viewpoints. Meanwhile, the predicted depth maps are sparse. Inferring depth information from a single image (monocular depth estimation) is an ill-posed problem. With the rapid development of deep neural networks, monocular depth estimation based on deep learning has been widely studied recently and achieved promising performance in accuracy. Meanwhile, dense depth maps are estimated from single images by deep neural networks in an end-to-end manner. In order to improve the accuracy of depth estimation, different kinds of network frameworks, loss functions and training strategies are proposed subsequently. Therefore, we survey the current monocular depth estimation methods based on deep learning in this review. Initially, we conclude several widely used datasets and evaluation indicators in deep learning-based depth estimation. Furthermore, we review some representative existing methods according to different training manners: supervised, unsupervised and semisupervised. Finally, we discuss the challenges and provide some ideas for future researches in monocular depth estimation.},
  accessDate = {2024-06-14 06:36:43},
  ISSN = {1674-7321, 1869-1900},
  volume = {63},
  journalAbbreviation = {Sci. China Technol. Sci.},
  key = {5IWGDN7U},
  date = {2020-09-00 09-2020},
  DOI = {10.1007/s11431-020-1582-8},
  issue = {9},
  title = {Monocular Depth Estimation Based On Deep Learning: An Overview},
  year = {2020},
  shortTitle = {Monocular Depth Estimation Based On Deep Learning},
}
@conferencePaper{vandijkHowNeuralNetworks2019,
  rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  author = {Van Dijk, Tom and De Croon, Guido},
  conferenceName = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  ISBN = {978-1-7281-4803-8},
  abstractNote = {Deep neural networks have lead to a breakthrough in depth estimation from single images. Recent work shows that the quality of these estimations is rapidly increasing. It is clear that neural networks can see depth in single images. However, to the best of our knowledge, no work currently exists that analyzes what these networks have learned.},
  url = {https://ieeexplore.ieee.org/document/9009532/},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {2183-2191},
  proceedingsTitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  language = {en},
  place = {Seoul, Korea (South)},
  date = {2019-10-00 2010-10-00},
  key = {XMZVKHSM},
  title = {How Do Neural Networks See Depth in Single Images?},
  publisher = {IEEE},
  DOI = {10.1109/ICCV.2019.00227},
  year = {2019},
  accessDate = {2025-01-04 22:19:24},
}
@journalArticle{khaldiOverviewSwarmRobotics2015a,
  date = {2015-09-17 2015-09-17},
  publicationTitle = {International Journal of Computer Applications},
  issue = {2},
  journalAbbreviation = {IJCA},
  author = {Khaldi, Belkacem and Cherif, Foudil},
  language = {en},
  libraryCatalog = {DOI.org (Crossref)},
  pages = {31-37},
  url = {http://www.ijcaonline.org/research/volume126/number2/khaldi-2015-ijca-906000.pdf},
  key = {N2A9WKS6},
  year = {2015},
  abstractNote = {As an emergent research area by which swarm intelligence is applied to multi-robot systems; swarm robotics (a very particular and peculiar sub-area of collective robotics) studies how to coordinate large groups of relatively simple robots through the use of local rules. It focuses on studying the design of large amount of relatively simple robots, their physical bodies and their controlling behaviors. Since its introduction in 2000, several successful experimentations had been realized, and till now more projects are under investigations. This paper seeks to give an overview of this domain research; for the aim to orientate the readers, especially those who are newly coming to this research field.},
  ISSN = {09758887},
  DOI = {10.5120/ijca2015906000},
  title = {An Overview of Swarm Robotics: Swarm Intelligence Applied to Multi-robotics},
  shortTitle = {An Overview of Swarm Robotics},
  accessDate = {2025-02-03 15:31:06},
  volume = {126},
}
@journalArticle{saxenaLearningDepthSingle,
  key = {J3QQAXIN},
  title = {Learning Depth from Single Monocular Images},
  year = {NA},
  abstractNote = {We consider the task of depth estimation from a single monocular image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufﬁcient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a discriminatively-trained Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models both depths at individual points as well as the relation between depths at different points. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps.},
  author = {Saxena, Ashutosh and Chung, Sung H and Ng, Andrew Y},
  language = {en},
  libraryCatalog = {Zotero},
}
